architecture:
  model_name: "vqdiffusion" # vqgan, vqvae, vqvae_transformer, vqgan_transformer, vqdiffusion
  vqvae:
    img_channels: 3 # 1, 3
    img_size: 256
    latent_channels: 256
    latent_size: 16
    intermediate_channels: [128, 128, 256, 256, 512]
    num_residual_blocks_encoder: 2
    num_residual_blocks_decoder: 3
    dropout: 0.0
    attention_resolution: [16]
    num_codebook_vectors: 1024
    resume_path: '/home/rhong5/research_pro/hand_modeling_pro/pytorch-vqgan/log/Oxford102Flower/vqgan/run_2024-07-15-15-05-14/vqvae.pt'
    train_vqvae: False # True, False
    freeze_weights: True # True, False

  transformer:
    sos_token: 0
    pkeep: 0.5
    block_size: 512
    n_layer: 12
    n_head: 16
    n_embd: 1024
    resume_path: None
    train_transformer: True
    freeze_weights: False
  
  diffusion:
    diffusion_steps: 500
    sampling_steps: 500
    noise_schedule: "linear"
    diffusion_type: 'Continuous' #'VQ_Official', 'Continuous'
    objective: 'pred_noise'
    resume_path: None
    train_diffusion: True
    freeze_weights: False
    indices_to_dist_fn: 'lookup_table' # 'lookup_table' or 'one_hot'
    gaussian_dim: 512
    distribute_dim: -1 # probability distribution dim, -1 for last dimension, 1 for second dimension


dataset:
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  batch_size: 100 # 20 for VAE, 100 for diffusion Unet2D,
  num_workers: 5
  dataset_name: 'Oxford102Flower' # mnist, cifar10, InterHand26M, Oxford102Flower
  get_hand_mask: True ### True or False; only for InterHand26M
  return_annotations: False
  max_train_samples: 'inf'
  max_val_samples: 'inf'  #600, 'inf'
  train_split: 'train' # train, val; val for convergence test


trainer:  
  num_epochs: 65
  log_dir: "log"
  
  vqvae:
    learning_rate: 2.25e-05
    beta1: 0.5
    beta2: 0.9
    perceptual_loss_factor: 1.0
    rec_loss_factor: 1.0
    perceptual_model: "vgg"

  transformer:
    learning_rate: 4.5e-06
    beta1: 0.9
    beta2: 0.95
  
  descriminator:
    disc_factor: 1.0
    disc_start: 100
    resume_path: None

  diffusion:
    learning_rate: 1.5e-04
    beta1: 0.6
    beta2: 0.95
    kl_loss_factor: 1.0
    rec_loss_factor: 1.0

