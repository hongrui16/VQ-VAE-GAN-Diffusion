architecture:
  model_name: "vqdiffusion" # vqgan, vqvae, vqvae_transformer, vqgan_transformer, vqdiffusion, gaussiandiffusion2d, gaussiandiffusion3d
  vqvae:
    img_channels: 3 # 1, 3
    img_size: 256
    latent_channels: 256
    latent_size: 16
    intermediate_channels: [128, 128, 256, 256, 512]
    num_residual_blocks_encoder: 2
    num_residual_blocks_decoder: 3
    dropout: 0.0
    attention_resolution: [16]
    num_codebook_vectors: 1024
    resume_path: '/home/rhong5/research_pro/hand_modeling_pro/pytorch-vqgan/log/Oxford102Flower/vqgan/run_2024-07-15-15-05-14/vqvae.pt'
    train_model: False # True, False
    freeze_weights: True # True, False
    batch_size: 20

  transformer:
    sos_token: 0
    pkeep: 0.5
    block_size: 512
    n_layer: 12
    n_head: 16
    n_embd: 1024
    resume_path: None
    train_model: True
    freeze_weights: False
  
  vqdiffusion: ## only for vqdiffusion
    img_size: 256
    diffusion_steps: 500
    sampling_steps: 500
    noise_schedule: "linear"
    diffusion_type: 'gaussiandiffusion3d' #'VQ_Official', 'gaussiandiffusion2d',  'gaussiandiffusion3d'
    objective: 'pred_noise'
    resume_path: None
    train_model: True
    freeze_weights: False
    indices_to_dist_fn: 'lookup_table' # 'lookup_table' or 'one_hot'
    gaussian_dim: 512
    distribute_dim: -1 # probability distribution dim, -1 for last dimension, 1 for second dimension

  gaussiandiffusion2d:
    resume_path: None
    img_size: 256
    diffusion_steps: 500
    sampling_steps: 500
    train_model: True
    freeze_weights: False

  gaussiandiffusion3d:
    resume_path: ''
    img_size: 256 # 28 for mnist
    train_model: True
    freeze_weights: False
    n_samples: 36
    model_base_dim: 64
    diffusion_steps: 500
    sampling_steps: 500
    input_channels: 1



dataset:
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  num_workers: 5
  dataset_name: 'Oxford102Flower' # mnist, cifar10, InterHand26M, Oxford102Flower
  get_hand_mask: True ### True or False; only for InterHand26M
  return_annotations: False
  max_train_samples: 'inf'
  max_val_samples: 'inf'  #600, 'inf'
  train_split: 'train' # train, val; val for convergence test


trainer:  
  num_epochs: 60
  log_dir: "log"
  num_workers: 5

  vqvae:
    learning_rate: 2.25e-04
    beta1: 0.5
    beta2: 0.9
    perceptual_loss_factor: 1.0
    rec_loss_factor: 1.0
    perceptual_model: "vgg"
    batch_size: 20

  transformer:
    learning_rate: 4.5e-04
    beta1: 0.9
    beta2: 0.95
    batch_size: 20
  
  descriminator:
    disc_factor: 1.0
    disc_start: 100
    resume_path: None

  vqdiffusion:
    learning_rate: 5.0e-04
    beta1: 0.6
    beta2: 0.95
    kl_loss_factor: 1.0
    rec_loss_factor: 1.0
    batch_size: 20

  gaussiandiffusion2d:
    learning_rate: 1.5e-04
    adam_betas: (0.65, 0.95)
    kl_loss_factor: 1.0
    rec_loss_factor: 1.0
    batch_size: 200


  gaussiandiffusion3d:
    learning_rate: 0.001
    kl_loss_factor: 1.0
    rec_loss_factor: 1.0
    batch_size: 500 # 500 for 28x28, 200 for 64x64
    model_ema_steps: 10
    model_ema_decay: 0.995
    no_clip: False