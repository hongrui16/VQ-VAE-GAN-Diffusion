architecture:
  model_name: "vqvae" # vqgan, vqvae, vqvae_transformer, vqgan_transformer, vqdiffusion, gaussiandiffusion2d, gaussiandiffusion3d
  vqvae:
    latent_channels: 256
    latent_size: 16
    intermediate_channels: [128, 128, 256, 256, 512]
    num_residual_blocks_encoder: 2
    num_residual_blocks_decoder: 3
    dropout: 0.0
    attention_resolution: [16]
    num_codebook_vectors: 1024
    resume_path: None #'/home/rhong5/research_pro/hand_modeling_pro/pytorch-vqgan/log/Oxford102Flower/vqgan/run_2024-07-15-15-05-14/vqvae.pt'
    train_model: True # True, False
    freeze_weights: False # True, False

  vqvae_transformer:
    sos_token: 0
    pkeep: 0.5
    block_size: 512
    n_layer: 12
    n_head: 16
    n_embd: 1024
    resume_path: None
    train_model: True
    freeze_weights: False
  
  vqdiffusion: ## only for vqdiffusion
    diffusion_steps: 1000
    sampling_steps: 1000
    noise_schedule: "linear"
    diffusion_type: 'gaussiandiffusion3d' #'VQ_Official', 'gaussiandiffusion2d',  'gaussiandiffusion3d'
    objective: 'pred_noise'
    resume_path: None
    train_model: True
    freeze_weights: False
    indices_to_dist_fn: 'lookup_table' # 'lookup_table' or 'one_hot'
    gaussian_dim: 96
    distribute_dim: -1 # probability distribution dim, -1 for last dimension, 1 for second dimension
    clipped_reverse_diffusion: True # False reulsts were bad.
    unet_dim: 3 # 3 for 3d, 2 for 2d
    sample_method: 'ddpm' # ddim or ddpm
    loss_fn: 'noise_mse' # 'noise_mse', loss_fn in ['noise_mse', 'elbo']
    return_all_timestamps: False
    compute_indices_recon_loss: True


  gaussiandiffusion2d:
    resume_path: None
    diffusion_steps: 1000
    sampling_steps: 1000
    train_model: True
    freeze_weights: False

  gaussiandiffusion3d:
    resume_path: ''
    train_model: True
    freeze_weights: False
    n_samples: 36
    model_base_dim: 64
    diffusion_steps: 1000
    sampling_steps: 1000



dataset:
  dataset_name: 'Oxford102Flower' # mnist, cifar10, InterHand26M, Oxford102Flower
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  num_workers: 5
  get_hand_mask: True ### True or False; only for InterHand26M
  return_annotations: False
  max_train_samples: 'inf'
  max_val_samples: 'inf'  #600, 'inf'
  train_split: 'train' # train, val; val for convergence test
  train_shuffle: True
  subset: True #  True for subset, False for full dataset
  img_channels:
    Oxford102Flower: 3
    InterHand26M: 3
    mnist: 1
    cifar10: 3

  img_size: 
    Oxford102Flower: 256
    InterHand26M: 256
    mnist: 28
    cifar10: 256
  
  batch_size:
    vqgan: 
      Oxford102Flower: 20
      InterHand26M: 20
      mnist: 200
      cifar10: 200
    vqvae:
      Oxford102Flower: 20
      InterHand26M: 20
      mnist: 200
      cifar10: 200
    vqgan_transformer:
      Oxford102Flower: 20
      InterHand26M: 20
      mnist: 200
      cifar10: 20
    vqdiffusion:
      Oxford102Flower: 20
      InterHand26M: 20
      mnist: 200
      cifar10: 20
    gaussiandiffusion2d:
      Oxford102Flower: 40
      InterHand26M: 40
      mnist: 500
      cifar10: 400
    gaussiandiffusion3d:
      Oxford102Flower: 20
      InterHand26M: 20
      mnist: 500
      cifar10: 400



trainer:  
  num_epochs: 60
  log_dir: "zlog"
  num_workers: 5

  vqvae:
    learning_rate: 2.25e-04
    beta1: 0.5
    beta2: 0.9
    perceptual_loss_factor: 1.0
    rec_loss_factor: 1.0
    perceptual_model: "vgg"

  vqvae_transformer:
    learning_rate: 4.5e-04
    beta1: 0.9
    beta2: 0.95
  
  descriminator:
    disc_factor: 1.0
    disc_start: 100
    resume_path: None

  vqdiffusion:
    learning_rate: 0.0001
    beta1: 0.65
    beta2: 0.95
    kl_loss_factor: 1.0
    rec_loss_factor: 1.0
    model_ema_steps: 10
    model_ema_decay: 0.995
    no_clip: False
    
  gaussiandiffusion2d:
    learning_rate: 1.5e-04
    adam_betas: (0.65, 0.95)
    kl_loss_factor: 1.0
    rec_loss_factor: 1.0


  gaussiandiffusion3d:
    learning_rate: 0.001
    model_ema_steps: 10
    model_ema_decay: 0.995
    no_clip: False